{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project 2: Segmentation of aerial images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: \n",
    "- exploratory data analysis to understand your dataset and your features\n",
    "- feature processing and engineering to clean your dataset and extract more meaningful information\n",
    "- implement and use machine learning methods on real data\n",
    "- analyze your model and generate predictions using those methods and report your findings\n",
    "\n",
    "**Submission deadline**. Dec 17th, 2020 (at 16:00 afternoon, sharp)\n",
    "\n",
    "Deliverables at a glance. (More details and grading criteria further down)\n",
    "- Written Report. You will write a maximum 4 page PDF report on your \f",
    "ndings, using LaTeX.\n",
    "- Code. In Python. External libraries are allowed, if properly cited.\n",
    "- Competitive Part. To give you immediate feedback and a fair ranking, we use the competition platform AIcrowd.com to score your predictions. You can submit whenever and almost as many times as you like, up until the final submission deadline.\n",
    "\n",
    "**Goal**: For this problem, we provide a set of satellite/aerial images acquired from GoogleMaps. We also provide ground-truth images where each pixel is labeled as {road, background}. Your goal is to train a classifier to segment roads in these images, i.e. assign a label {road=1, background=0} to each pixel. Please see detailed instructions on the course github.\n",
    "\n",
    "Good summary:https://neptune.ai/blog/image-segmentation-in-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "from PIL import Image\n",
    "\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.utils.mem import *\n",
    "import tensorflow as tf\n",
    "from torchvision.models import vgg16_bn\n",
    "import torchvision.transforms as transforms\n",
    "from skimage import measure\n",
    "from numpy import linalg as LA\n",
    "import shutil\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# helper functions from lab (load csv, create prediction, etc)\n",
    "from helper_functions.helper_functions import *\n",
    "# script to reconstruct an image from the sample submission file\n",
    "from helper_functions.submission_to_mask import *\n",
    "\n",
    "#script to make a submission file from a binary image:\n",
    "from helper_functions.mask_to_submission import *\n",
    "\n",
    "# Baseline for machine learning project on road segmentation.\n",
    "from helper_functions.tf_aerial_images import *\n",
    "\n",
    "# Baseline for machine learning project on road segmentation.\n",
    "from helper_functions.helper_Marijn import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set CUDA if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File descriptions:\n",
    "- `training` - the training set consisting of images with their ground truth\n",
    "- `test_set_images` - the test set\n",
    "- `sampleSubmission.csv` - a sample submission file in the correct format\n",
    "- `mask_to_submission.py` - script to make a submission file from a binary image\n",
    "- `submission_to_mask.py` - script to reconstruct an image from the sample submission file\n",
    "- `tf_aerial_images.py` - Baseline for machine learning project on road segmentation. This simple baseline consits of a CNN with two convolutional+pooling layers with a soft-max loss\n",
    "\n",
    "\n",
    "The sample submission file contains two columns: \n",
    "- first column corresponds to the image id followed by the x and y top-left coordinate of the image patch (16x16 pixels)\n",
    "- second column is the label assigned to the image patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paths to data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../data/training/')\n",
    "path_test = Path('../data/test_set_images/')\n",
    "\n",
    "if not (path /'images').exists():\n",
    "    (path /'images').mkdir()\n",
    "    \n",
    "if not (path / 'groundtruth').exists():\n",
    "    (path / 'groundtruth').mkdir()\n",
    "\n",
    "path_train = path /'images'\n",
    "path_GT = path / 'groundtruth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Pixel range: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train_names = get_image_files(path_train)\n",
    "f_gt_names = get_image_files(path_GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = open_mask(f_gt_names[0])\n",
    "img = open_image(f_train_names[0])\n",
    "img_gt = open_image(f_gt_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize = (10, 5))\n",
    "axs[0].hist(img.data[0])\n",
    "axs[0].set_title('Raw image')\n",
    "axs[1].hist(mask.data[0])\n",
    "axs[1].set_title('Mask')\n",
    "axs[2].hist(img_gt.data[0])\n",
    "axs[2].set_title('gt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: masks shifts data to `[0,255]` pixel range. Original data also in 0,1 pixel range. Change everything to 0,255 ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - np.min(img)\n",
    "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
    "    return rimg\n",
    "\n",
    "# Concatenate an image and its groundtruth\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = np.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change one image to 0,255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(img_float_to_uint8(img.data.numpy())[0,:,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = open_mask(f_gt_names[0])\n",
    "img = open_image(f_train_names[0])\n",
    "mask.show(figsize=(5, 5),  cmap='Greys_r'), img.show(figsize=(5, 5))\n",
    "src_size = np.array(mask.shape)[1:]\n",
    "print(f'Mask shape: {np.array(mask.shape)}')\n",
    "print(f'Image shape: {np.array(img.shape)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: problem not same pixel range ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create patches: \n",
    "\n",
    "https://medium.com/analytics-vidhya/a-simple-cloud-detection-walk-through-using-convolutional-neural-network-cnn-and-u-net-and-bc745dda4b04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train_names = get_image_files(path_train)\n",
    "f_gt_names = get_image_files(path_GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patches from input images\n",
    "patch_size = 16  # each patch is 16*16 pixels\n",
    "\n",
    "# Number of images to extract patches\n",
    "N = 20\n",
    "img_patches = [\n",
    "    img_crop(mpimg.imread(img), patch_size, patch_size)\n",
    "    for img in f_train_names[:N]\n",
    "]\n",
    "gt_patches = [\n",
    "    img_crop(mpimg.imread(img), patch_size, patch_size) for img in f_gt_names[:N]\n",
    "]\n",
    "\n",
    "# Linearize list of patches\n",
    "img_patches = np.asarray([\n",
    "    img_patches[i][j] for i in range(len(img_patches))\n",
    "    for j in range(len(img_patches[i]))\n",
    "])\n",
    "gt_patches = np.asarray([\n",
    "    gt_patches[i][j] for i in range(len(gt_patches))\n",
    "    for j in range(len(gt_patches[i]))\n",
    "])\n",
    "\n",
    "print(f'Number of patches: {len(img_patches)} created from {N} images')\n",
    "print(f'Shape of patches: {img_patches.shape[1]}')\n",
    "\n",
    "patch_shape = img_patches.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create RGB PIL image from patches and save them. To meet the fast.ai requirements, we should organize our data into data/images and data/labels manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (path/'patches/images').exists():\n",
    "    (path/'patches/images').mkdir()\n",
    "\n",
    "if not (path/'patches/labels').exists():\n",
    "    (path/'patches/labels').mkdir()\n",
    "    \n",
    "path_data = Path('../data/training/patches')\n",
    "path_lbl = path_data/'labels'\n",
    "path_img = path_data/'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(img_patches)):\n",
    "    rgb_patch = Image.fromarray((256*img_patches[i]).astype(np.uint8), 'RGB')\n",
    "    rgb_patch.save(path_img/f'patch_{i}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to convert the ground truth images to values 0 (no road) and 1 (road) and store them into a folder called ‘labels’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = open_image(f_gt_names[0])\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create one mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread(f_gt_names[0])\n",
    "im = Image.fromarray((np.where(img > 0.5, 1, 0)*255).astype(np.uint8), 'L')\n",
    "np.unique(im)\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create all masks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(gt_patches)):\n",
    "    # change values from 255 to 1\n",
    "    img = gt_patches[i]\n",
    "    im = Image.fromarray((np.where(img > 0.5, 1, 0)*255).astype(np.uint8))\n",
    "    im.save(path_lbl/f'patch_{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get images and labels filenames\n",
    "img_names = get_image_files(path_img)\n",
    "lbl_names = get_image_files(path_lbl)\n",
    "print(len(img_names), len(lbl_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to map images to respective masks and test it with open_image and open_mask functions that load them into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lbl_fn(img_fn: Path):\n",
    "    img_name = img_fn.name\n",
    "    return img_fn.parent.parent / ('labels/' + img_name)\n",
    "\n",
    "\n",
    "fname = path_img / 'patch_50.png'\n",
    "img = open_image(fname)\n",
    "mask = open_mask(get_lbl_fn(fname))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "img.show(ax[0])\n",
    "mask.show(ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using the entire set of 8400 images as training, we will let the library divide them into training (80%) and validation (20%) sets. Also, we will use some data augmentation. Data augmentation is a technique to increase the number of training samples by applying some random transformations like rotation, flipping, warp, and others.  Data Bunch keeps track of the samples and respective labels and, in the case of image segmentation, also merges both for a fast visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegLabelListCustom(SegmentationLabelList):\n",
    "    def open(self, fn):\n",
    "        return open_mask(fn, div=True)\n",
    "\n",
    "\n",
    "class SegItemListCustom(SegmentationItemList):\n",
    "    _label_cls = SegLabelListCustom\n",
    "\n",
    "\n",
    "src = (SegItemListCustom.from_folder(\n",
    "    path_img).split_by_rand_pct().label_from_func(get_lbl_fn,\n",
    "                                                  classes=['rest', 'road']))\n",
    "\n",
    "data = (src.transform(get_transforms(flip_vert=True),\n",
    "                      size=patch_shape,\n",
    "                      tfm_y=True).databunch(bs=4).normalize(imagenet_stats))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Model:\n",
    "pre-trained ResNet 34 version of the U-Net, that has 34 layers in the contracting path. To create it, we will define a accuracy function, to measure the performance of the mode, the weight decay (regularization to avoid overfitting of the model) value and the learning rate (rate that will be multiplied to the gradient to adjust parameters during back-propagation step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_metric(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    return (input.argmax(dim=1)==target).float().mean()\n",
    "\n",
    "wd = 1e-2\n",
    "\n",
    "lr=1e-3\n",
    "\n",
    "learn = unet_learner(data, models.resnet34, metrics=acc_metric, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First cycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fit(save_name, lrs=lr, pct_start=0.9):\n",
    "    \"\"\"\n",
    "    do_fit: fits during 10 epochs with feature loss. \n",
    "    \"\"\"\n",
    "    learn.fit_one_cycle(1, lrs, pct_start=pct_start)\n",
    "    learn.save(save_name, return_path=True)\n",
    "    learn.show_results(rows=1, imgsize=10)\n",
    "    learn.recorder.plot_losses()\n",
    "    learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('sim{}_1a'.format(sim), slice(lr * 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "img = learn.data.valid_ds.x[22]\n",
    "mask = learn.data.valid_ds.y[22]\n",
    "pred = learn.predict(img)[0]\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(12,6))\n",
    "\n",
    "img.show(ax[0])\n",
    "mask.show(ax[1])\n",
    "pred.show(ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create predictions :\n",
    "Your predictions must be in .csv format, see sample-submission.csv. You must use the same datapoint ids as in the test set test.csv. To generate .csv output from Python, use our provided helper functions in helpers.py (see Project 1 folder on github)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (Path('../data/test_set_images/all_tests')).exists():\n",
    "    (Path('../data/test_set_images/all_tests')).mkdir()\n",
    "    \n",
    "if not (Path('../data/test_set_images/all_tests/patches')).exists():\n",
    "    (Path('../data/test_set_images/all_tests/patches')).mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! find ../data/test_images -type f -name \"*.png\" -exec mv \"{}\" ../data/test_images/all_tests \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = Path('../data/test_set_images/all_tests')\n",
    "fnames_test = get_image_files(path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
    "def create_patches_test(test_file_name):\n",
    "    img_number = int(re.search(r\"\\d+\", str(test_file_name)).group(0))\n",
    "    im = mpimg.imread(Path(test_file_name))\n",
    "    patch_size = 16\n",
    "    for j in range(0, im.shape[1], patch_size):\n",
    "        for i in range(0, im.shape[0], patch_size):\n",
    "            # Create patch and save it because dont know any better yet\n",
    "            patch = im[i:i + patch_size, j:j + patch_size]\n",
    "            rgb_patch = Image.fromarray((256*patch).astype(np.uint8), 'RGB')\n",
    "            name = \"{:03d}_{}_{}.png\".format(img_number, j, i)\n",
    "            rgb_patch.save(path_test_patches/name)\n",
    "            \n",
    "            # prediction from patch: \n",
    "            tensor = open_image(path_test_patches/name)\n",
    "            \n",
    "            prediction = learn.predict(tensor)\n",
    "            label = patch_to_label(prediction[0].data.numpy())\n",
    "            \n",
    "            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masks_to_submission(submission_filename, image_filenames):\n",
    "    \"\"\"Converts images into a submission file\"\"\"\n",
    "    with open(submission_filename, 'w') as f:\n",
    "        f.write('id,prediction\\n')\n",
    "        for fn in image_filenames:\n",
    "            f.writelines('{}\\n'.format(s) for s in create_patches_test(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_to_submission('dummy_submission.csv', test_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
