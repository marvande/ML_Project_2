{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Project Vince Version",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfSDQimsqx3W"
      },
      "source": [
        "import zipfile\n",
        "# with zipfile.ZipFile(\"colab.zip\", 'r') as zip_ref:\n",
        "    # zip_ref.extractall(\".\")\n",
        "\n",
        "import gzip\n",
        "import os\n",
        "import sys\n",
        "import urllib\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "import code\n",
        "import tensorflow.python.platform\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow_addons as tfa\n",
        "import source.mask_to_submission as submission_maker\n",
        "import source.constants as cst\n",
        "import source.images as images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxX7ExuOrHPi"
      },
      "source": [
        "def error_rate(predictions, labels):\n",
        "    \"\"\"Return the error rate based on dense predictions and 1-hot labels.\"\"\"\n",
        "    return 100.0 - (\n",
        "        100.0 *\n",
        "        numpy.sum(numpy.argmax(predictions, 1) == numpy.argmax(labels, 1)) /\n",
        "        predictions.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2sdBAVlrKPO"
      },
      "source": [
        "# Write predictions from neural network to a file\n",
        "def write_predictions_to_file(predictions, labels, filename):\n",
        "    max_labels = numpy.argmax(labels, 1)\n",
        "    max_predictions = numpy.argmax(predictions, 1)\n",
        "    file = open(filename, \"w\")\n",
        "    n = predictions.shape[0]\n",
        "    for i in range(0, n):\n",
        "        file.write(max_labels(i) + ' ' + max_predictions(i))\n",
        "    file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH95jelGrOEB"
      },
      "source": [
        "# Print predictions from neural network\n",
        "def print_predictions(predictions, labels):\n",
        "    max_labels = numpy.argmax(labels, 1)\n",
        "    max_predictions = numpy.argmax(predictions, 1)\n",
        "    print(str(max_labels) + ' ' + str(max_predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8MyHxnErRxJ"
      },
      "source": [
        "# Convert array of labels to an image\n",
        "def label_to_img(imgwidth, imgheight, w, h, labels):\n",
        "    array_labels = numpy.zeros([imgwidth, imgheight])\n",
        "    idx = 0\n",
        "    for i in range(0, imgheight, h):\n",
        "        for j in range(0, imgwidth, w):\n",
        "            if labels[idx][0] > 0.5:  # bgrd\n",
        "                l = 0\n",
        "            else:\n",
        "                l = 1\n",
        "            array_labels[j:j+w, i:i+h] = l\n",
        "            idx = idx + 1\n",
        "    return array_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsEPV4aLrSjD"
      },
      "source": [
        "# Make an image summary for 4d tensor image with index idx\n",
        "def get_image_summary(img, idx=0):\n",
        "    V = tf.slice(img, (0, 0, 0, idx), (1, -1, -1, 1))\n",
        "    img_w = img.get_shape().as_list()[1]\n",
        "    img_h = img.get_shape().as_list()[2]\n",
        "    min_value = tf.reduce_min(V)\n",
        "    V = V - min_value\n",
        "    max_value = tf.reduce_max(V)\n",
        "    V = V / (max_value * cst.PIXEL_DEPTH)\n",
        "    V = tf.reshape(V, (img_w, img_h, 1))\n",
        "    V = tf.transpose(V, (2, 0, 1))\n",
        "    V = tf.reshape(V, (-1, img_w, img_h, 1))\n",
        "    return V"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD2xhs5RrUhT"
      },
      "source": [
        "# Make an image summary for 3d tensor image with index idx\n",
        "def get_image_summary_3d(img):\n",
        "    V = tf.slice(img, (0, 0, 0), (1, -1, -1))\n",
        "    img_w = img.get_shape().as_list()[1]\n",
        "    img_h = img.get_shape().as_list()[2]\n",
        "    V = tf.reshape(V, (img_w, img_h, 1))\n",
        "    V = tf.transpose(V, (2, 0, 1))\n",
        "    V = tf.reshape(V, (-1, img_w, img_h, 1))\n",
        "    return V"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCtIov0crYQ_"
      },
      "source": [
        "# Get a concatenation of the prediction and groundtruth for given input file\n",
        "def get_prediction_with_groundtruth(filename, image_idx, is_training = True):\n",
        "\n",
        "    imageid = \"\"\n",
        "    if is_training:\n",
        "        imageid = \"satImage_%.3d\" % image_idx\n",
        "    else:\n",
        "        imageid = \"test_%d/test_%d\" % (image_idx, image_idx)\n",
        "    image_filename = filename + imageid + \".png\"\n",
        "    img = mpimg.imread(image_filename)\n",
        "\n",
        "    img_prediction = get_prediction(img)\n",
        "    cimg = images.concatenate_images(img, img_prediction)\n",
        "\n",
        "    return cimg "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK_d4gecraXo"
      },
      "source": [
        "def get_groundtruth(filename, image_idx, is_training = True):\n",
        "    imageid = \"\"\n",
        "    if is_training:\n",
        "        imageid = \"satImage_%.3d\" % image_idx\n",
        "    else:\n",
        "        imageid = \"test_%d/test_%d\" % (image_idx, image_idx)\n",
        "    image_filename = filename + imageid + \".png\"\n",
        "    img = mpimg.imread(image_filename)\n",
        "    # blank = Image.new(\"L\", (0, 0))\n",
        "    return get_prediction(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDXsxK4Rrb6x"
      },
      "source": [
        "# Get prediction overlaid on the original image for given input file\n",
        "def get_prediction_with_overlay(filename, image_idx, is_training = True):\n",
        "    imageid = \"\"\n",
        "    if is_training:\n",
        "        imageid = \"satImage_%.3d\" % image_idx\n",
        "    else:\n",
        "        imageid = \"test_%d/test_%d\" % (image_idx, image_idx)\n",
        "    image_filename = filename + imageid + \".png\"\n",
        "    img = mpimg.imread(image_filename)\n",
        "\n",
        "    img_prediction = get_prediction(img)\n",
        "    oimg = images.make_img_overlay(img, img_prediction)\n",
        "\n",
        "    return oimg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRw8F76Yre3Q"
      },
      "source": [
        "def get_unet():\n",
        "    inputs = layers.Input((200, 200, 3), name=\"input_layer\")\n",
        "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = layers.MaxPooling2D((2, 2), (2, 2))(conv1)\n",
        "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = layers.MaxPooling2D((2, 2), (2, 2))(conv2)\n",
        "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = layers.MaxPooling2D((2, 2), (2, 2))(conv3)\n",
        "    conv4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    pool4 = layers.MaxPooling2D((2, 2), (2, 2))(conv4)\n",
        "    conv5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n",
        "    up6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
        "    cropped6 = tf.image.resize_with_crop_or_pad(conv4, up6.shape[1], up6.shape[2])\n",
        "    conc6 = layers.concatenate([up6, cropped6], axis=3)\n",
        "    conv6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conc6)\n",
        "    conv6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
        "    up7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
        "    cropped7 = tf.image.resize_with_crop_or_pad(conv3, up7.shape[1], up7.shape[2])\n",
        "    conc7 = layers.concatenate([up7, cropped7], axis=3)\n",
        "    conv7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conc7)\n",
        "    conv7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
        "    up8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
        "    cropped8 = tf.image.resize_with_crop_or_pad(conv2, up8.shape[1], up8.shape[2])\n",
        "    conc8 = layers.concatenate([up8, cropped8], axis=3)\n",
        "    conv8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conc8)\n",
        "    conv8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
        "    up9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
        "    cropped9 = tf.image.resize_with_crop_or_pad(conv1, up9.shape[1], up9.shape[2])\n",
        "    conc9 = layers.concatenate([up9, cropped9], axis=3)\n",
        "    conv9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conc9)\n",
        "    conv10 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
        "    conv10 = layers.Conv2D(1, (1, 1), activation='sigmoid', name=\"output_layer\")(conv10)\n",
        "    conv10 = layers.Reshape((192, 192))(conv10)\n",
        "\n",
        "    unet = tf.keras.Model(inputs=[inputs], outputs=[conv10])\n",
        "    # unet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    # unet.compile(optimizer='adam', loss=tfa.losses.SigmoidFocalCrossEntropy(alpha=0.1, gamma=2.0), metrics=['accuracy', tfa.metrics.F1Score(num_classes=2, average=\"micro\")])\n",
        "    unet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', tfa.metrics.F1Score(num_classes=2, average=\"micro\")])\n",
        "    return unet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro7fHSkkrfn6"
      },
      "source": [
        "def train_unet(unet):\n",
        "    \n",
        "    train_data_filename = cst.TRAIN_DIR + 'images/'\n",
        "    train_labels_filename = cst.TRAIN_DIR + 'groundtruth/' \n",
        "\n",
        "    # Extract it into numpy arrays.\n",
        "    train_data = images.load_training(train_data_filename, cst.TRAINING_SIZE)\n",
        "    train_labels = images.load_groundtruths(train_labels_filename, cst.TRAINING_SIZE)\n",
        "\n",
        "    print(\"DATA SHAPE \" + str(train_data.shape))\n",
        "    print(\"TRAIN_LABELS SHAPE \" + str(train_labels.shape))\n",
        "\n",
        "    unet.summary()\n",
        "    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(cst.SAVE_NETWORK_FILE, monitor='loss', save_best_only=True)\n",
        "\n",
        "    output_shape = unet.get_layer(\"output_layer\").output_shape\n",
        "    margin = int((train_labels.shape[1] - output_shape[1]) / 2)\n",
        "    right_margin = int(output_shape[1] + margin)\n",
        "    train_labels = train_labels[:,margin:right_margin,margin:right_margin]\n",
        "\n",
        "    unet.fit(train_data, train_labels, epochs=cst.NUM_EPOCHS, validation_split=0.2, batch_size=cst.BATCH_SIZE, callbacks=[model_checkpoint])\n",
        "    unet.save(cst.SAVE_NETWORK_FILE)\n",
        "    train_data = None\n",
        "    train_labels = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf8iLYiFrjiM"
      },
      "source": [
        "def predict(train_before = False):\n",
        "    unet = get_unet()\n",
        "    if train_before or not os.path.exists(cst.SAVE_NETWORK_FILE):\n",
        "        train_unet(unet)\n",
        "    else:\n",
        "        print(\"LOADING SAVED WEIGHTS\")\n",
        "        unet.load_weights(cst.SAVE_NETWORK_FILE)\n",
        "\n",
        "    input_size = unet.get_layer(\"input_layer\").input_shape[0][1]\n",
        "    output_size = unet.get_layer(\"output_layer\").output_shape[1]\n",
        "    test_data = images.load_test(cst.TEST_DIR, cst.TEST_SIZE, input_size, output_size)\n",
        "    \n",
        "    masks = unet.predict(test_data, verbose=1)\n",
        "    numpy.save(\"image_mask.npy\", masks)\n",
        "\n",
        "    return masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwH4y6jqrmNQ"
      },
      "source": [
        "def generate_masks(masks):\n",
        "    predictions = []\n",
        "    if not os.path.isdir(cst.OUTPUT_DIR):\n",
        "        os.mkdir(cst.OUTPUT_DIR)\n",
        "    print(masks.shape)\n",
        "    for i in range(0, 800, 16):\n",
        "        mask_line_1 = numpy.concatenate((masks[i], masks[i + 1], masks[i + 2], masks[i + 3]), axis=1)\n",
        "        mask_line_2 = numpy.concatenate((masks[i + 4], masks[i + 5], masks[i + 6], masks[i + 7]), axis=1)\n",
        "        mask_line_3 = numpy.concatenate((masks[i + 8], masks[i + 9], masks[i + 10], masks[i + 11]), axis=1)\n",
        "        mask_line_4 = numpy.concatenate((masks[i + 12], masks[i + 13], masks[i + 14], masks[i + 15]), axis=1)\n",
        "        mask = numpy.concatenate((mask_line_1, mask_line_2, mask_line_3, mask_line_4), axis=0)[0:608, 0:608, :]\n",
        "        mask = mask.reshape((608, 608))\n",
        "        mask = numpy.around(mask).astype('float32')\n",
        "        for k in range(0, 608, 16):\n",
        "            for l in range(0, 608, 16):\n",
        "                patch = mask[k:k + 16, l:l + 16]\n",
        "                summed = numpy.sum(patch)\n",
        "                if summed >= (16 * 16 * cst.PIXEL_THRESHOLD):\n",
        "                    mask[k:k + 16, l:l + 16].fill(1)\n",
        "                else:\n",
        "                    mask[k:k + 16, l:l + 16].fill(0)\n",
        "        predictions.append(mask)\n",
        "        Image.fromarray(images.img_float_to_uint8(mask)).save(cst.OUTPUT_DIR + \"mask_%d.png\" % ((i / 16) + 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KSMnlMfroSV"
      },
      "source": [
        "generate_masks(predict(train_before = True))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}