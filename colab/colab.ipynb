{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "colab.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "lxX7ExuOrHPi"
   },
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "if not os.path.isdir(\"source\"):\n",
    "   with zipfile.ZipFile(\"source.zip\", 'r') as zip_ref:\n",
    "      zip_ref.extractall(\".\")\n",
    "\n",
    "if not os.path.isdir(\"data\"):\n",
    "   with zipfile.ZipFile(\"data.zip\", 'r') as zip_ref:\n",
    "      zip_ref.extractall(\".\")  "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hfSDQimsqx3W"
   },
   "source": [
    "import gzip\n",
    "import sys\n",
    "import urllib\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import code\n",
    "import tensorflow.python.platform\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.backend as backend\n",
    "import tensorflow_addons as tfa\n",
    "import source.mask_to_submission as submission_maker\n",
    "import source.constants as cst\n",
    "import source.images as images"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Brhj66-IaADZ"
   },
   "source": [
    "def recall(y, predictions):\n",
    "    true_positives = backend.sum(backend.round(backend.clip(y * predictions, 0, 1)))\n",
    "    possible_positives = backend.sum(backend.round(backend.clip(y, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + backend.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y, predictions):\n",
    "    true_positives = backend.sum(backend.round(backend.clip(y * predictions, 0, 1)))\n",
    "    predicted_positives = backend.sum(backend.round(backend.clip(predictions, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + backend.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_metric(y, predictions):\n",
    "    pre = precision(y, predictions)\n",
    "    rec = recall(y, predictions)\n",
    "    return 2 * ((pre * rec) / (pre + rec + backend.epsilon()))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jUsdwqI0zAGz"
   },
   "source": [
    "class FocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=1.0, gamma=2.0, reduction=tf.keras.losses.Reduction.AUTO, name='focal_loss'):\n",
    "        super().__init__(reduction=reduction, name=name)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.expand_dims(y_true, axis=-1)\n",
    "\n",
    "        bce_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        pt = tf.math.exp(-bce_loss)\n",
    "\n",
    "        return self.alpha * tf.math.pow(1-pt, self.gamma) * bce_loss -\\\n",
    "               (1-self.alpha) * tf.math.pow(pt, self.gamma) * tf.math.log(1-pt)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QRw8F76Yre3Q"
   },
   "source": [
    "def get_unet():\n",
    "    inputs = layers.Input((200, 200, 3), name=\"input_layer\")\n",
    "    drop1 = layers.Dropout(cst.DROPOUT_PROBABILITY)(inputs)\n",
    "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(drop1)\n",
    "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D((2, 2), (2, 2))(conv1)\n",
    "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D((2, 2), (2, 2))(conv2)\n",
    "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = layers.MaxPooling2D((2, 2), (2, 2))(conv3)\n",
    "    conv4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = layers.MaxPooling2D((2, 2), (2, 2))(conv4)\n",
    "    conv5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    up6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "    cropped6 = tf.image.resize_with_crop_or_pad(conv4, up6.shape[1], up6.shape[2])\n",
    "    conc6 = layers.concatenate([up6, cropped6], axis=3)\n",
    "    conv6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conc6)\n",
    "    conv6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    up7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "    cropped7 = tf.image.resize_with_crop_or_pad(conv3, up7.shape[1], up7.shape[2])\n",
    "    conc7 = layers.concatenate([up7, cropped7], axis=3)\n",
    "    conv7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conc7)\n",
    "    conv7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    up8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "    cropped8 = tf.image.resize_with_crop_or_pad(conv2, up8.shape[1], up8.shape[2])\n",
    "    conc8 = layers.concatenate([up8, cropped8], axis=3)\n",
    "    conv8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conc8)\n",
    "    conv8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    up9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "    cropped9 = tf.image.resize_with_crop_or_pad(conv1, up9.shape[1], up9.shape[2])\n",
    "    conc9 = layers.concatenate([up9, cropped9], axis=3)\n",
    "    conv9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conc9)\n",
    "    drop10 = layers.Dropout(cst.DROPOUT_PROBABILITY)(conv9)\n",
    "    conv10 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(drop10)\n",
    "    conv10 = layers.Conv2D(1, (1, 1), activation='sigmoid', name=\"output_layer\")(conv10)\n",
    "\n",
    "    unet = tf.keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "    unet.compile(optimizer='adam', loss=FocalLoss(alpha=0.75, gamma=5.0), metrics=[f1_metric, 'accuracy'])\n",
    "    return unet"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ro7fHSkkrfn6"
   },
   "source": [
    "def train_unet(unet):\n",
    "    \n",
    "    train_data_filename = cst.TRAIN_DIR + 'images/'\n",
    "    train_labels_filename = cst.TRAIN_DIR + 'groundtruth/' \n",
    "\n",
    "    # Extract it into numpy arrays.\n",
    "    train_data, mean_train, std_train = images.load_training(train_data_filename, cst.TRAINING_SIZE)\n",
    "    train_labels = images.load_groundtruths(train_labels_filename, cst.TRAINING_SIZE)\n",
    "\n",
    "    print(\"DATA SHAPE \" + str(train_data.shape))\n",
    "    print(\"TRAIN_LABELS SHAPE \" + str(train_labels.shape))\n",
    "\n",
    "    unet.summary()\n",
    "    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(cst.SAVE_NETWORK_FILE, monitor='f1_metric', save_best_only=True)\n",
    "\n",
    "    output_shape = unet.get_layer(\"output_layer\").output_shape\n",
    "    margin = int((train_labels.shape[1] - output_shape[1]) / 2)\n",
    "    right_margin = int(output_shape[1] + margin)\n",
    "    train_labels = train_labels[:,margin:right_margin,margin:right_margin]\n",
    "\n",
    "    unet.fit(train_data, train_labels, epochs=cst.NUM_EPOCHS, validation_split=0.0, batch_size=cst.BATCH_SIZE, callbacks=[model_checkpoint])\n",
    "    # unet.save(cst.SAVE_NETWORK_FILE)\n",
    "    train_data = None\n",
    "    train_labels = None\n",
    "\n",
    "    return mean_train, std_train"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Jf8iLYiFrjiM"
   },
   "source": [
    "def predict():\n",
    "    \n",
    "    unet = get_unet()\n",
    "    mean_train, std_train = train_unet(unet)\n",
    "\n",
    "    input_size = unet.get_layer(\"input_layer\").input_shape[0][1]\n",
    "    output_size = unet.get_layer(\"output_layer\").output_shape[1]\n",
    "\n",
    "    test_data = images.load_test(cst.TEST_DIR, cst.TEST_SIZE, input_size, output_size, mean_train, std_train)\n",
    "    \n",
    "    masks = unet.predict(test_data, verbose=1)\n",
    "    numpy.save(\"image_mask.npy\", masks)\n",
    "\n",
    "    return masks"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dwH4y6jqrmNQ"
   },
   "source": [
    "def generate_masks(masks):\n",
    "    predictions = []\n",
    "    if not os.path.isdir(cst.OUTPUT_DIR):\n",
    "        os.mkdir(cst.OUTPUT_DIR)\n",
    "    print(masks.shape)\n",
    "    for i in range(0, 800, 16):\n",
    "        mask_line_1 = numpy.concatenate((masks[i], masks[i + 1], masks[i + 2], masks[i + 3]), axis=1)\n",
    "        mask_line_2 = numpy.concatenate((masks[i + 4], masks[i + 5], masks[i + 6], masks[i + 7]), axis=1)\n",
    "        mask_line_3 = numpy.concatenate((masks[i + 8], masks[i + 9], masks[i + 10], masks[i + 11]), axis=1)\n",
    "        mask_line_4 = numpy.concatenate((masks[i + 12], masks[i + 13], masks[i + 14], masks[i + 15]), axis=1)\n",
    "        mask = numpy.concatenate((mask_line_1, mask_line_2, mask_line_3, mask_line_4), axis=0)[0:608, 0:608, :]\n",
    "        mask = mask.reshape((608, 608))\n",
    "        mask = numpy.around(mask).astype('float64')\n",
    "        for k in range(0, 608, 16):\n",
    "            for l in range(0, 608, 16):\n",
    "                patch = mask[k:k + 16, l:l + 16]\n",
    "                summed = numpy.sum(patch)\n",
    "                if summed >= (16 * 16 * cst.PIXEL_THRESHOLD):\n",
    "                    mask[k:k + 16, l:l + 16].fill(1)\n",
    "                else:\n",
    "                    mask[k:k + 16, l:l + 16].fill(0)\n",
    "        predictions.append(mask)\n",
    "        Image.fromarray(images.img_float_to_uint8(mask)).save(cst.OUTPUT_DIR + \"mask_%d.png\" % ((i / 16) + 1))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4KSMnlMfroSV"
   },
   "source": [
    "generate_masks(predict())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hav7dOTNUn6N"
   },
   "source": [
    "submission_filename = 'submit.csv'\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = 'data/predictions/mask_' + '%d' % i + '.png'\n",
    "    print(image_filename)\n",
    "    image_filenames.append(image_filename)\n",
    "submission_maker.masks_to_submission(submission_filename, *image_filenames)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}